# Research

## Transformer
paper : https://arxiv.org/abs/1706.03762

## BERT
paper : https://arxiv.org/abs/1810.04805

## Symbolic Music Genre Transfer with CycleGAN
paper : https://arxiv.org/abs/1809.07575  
github : https://github.com/sumuzhao/CycleGAN-Music-Style-Transfer

## Music Transformer
paper : https://arxiv.org/abs/1809.04281  
github : https://github.com/jason9693/MusicTransformer-tensorflow2.0

## REMI
paper : https://arxiv.org/abs/2002.00212  
github : https://github.com/YatingMusic/remi

## Music BERT
paper : https://arxiv.org/abs/2106.05630  
github : https://github.com/microsoft/muzic/tree/main/musicbert

## Midi BERT
paper : https://arxiv.org/abs/2107.05223  
github : https://github.com/wazenmai/MIDI-BERT

## MuseMorphose
paper : https://arxiv.org/abs/2105.04090  
github : https://github.com/YatingMusic/MuseMorphose

## TransGAN
paper : https://arxiv.org/abs/2102.07074  
github : https://github.com/VITA-Group/TransGAN  
github : https://github.com/asarigun/TransGAN ← こっちの方がわかりやすいかも

## Cramming BERT
paper : https://arxiv.org/abs/2212.14034  
github : https://github.com/JonasGeiping/cramming

## Sparse Transformer
paper : https://arxiv.org/abs/1904.10509  
github : https://github.com/openai/sparse_attention

## Instruct GPT
paper : https://arxiv.org/abs/2203.02155  
github : https://github.com/openai/following-instructions-human-feedback


